"""pdfbot

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1scL3-VJEoa1xBnNNZga_U2pMKcsQRFfO
"""

!pip3 install pyTelegrambotAPI

from google.colab import userdata
import telebot

telegram_bot_token = 'TELETOKEN'  # @param {type: "string"}

try:
  TELEGRAM_API_KEY=userdata.get(telegram_bot_token)
  bot = telebot.TeleBot(TELEGRAM_API_KEY)
  bot.get_me()
except userdata.SecretNotFoundError as e:
   print(f'Secret not found\n\nThis expects you to create a secret named {telegram_bot_token} in Colab\n\nMessage botfather on telegram to create a new bot and get that token\n\nStore that in the secrets section on the left side of the notebook (key icon)\n\nName the secret {telegram_bot_token}')
   raise e
except userdata.NotebookAccessError as e:
  print(f'You need to grant this notebook access to the {telegram_bot_token} secret in order for the notebook to access your Telegram Bot on your behalf.')
  raise e
except Exception as e:
  # unknown error
  print(f"There was an unknown error. Ensure you have a secret {telegram_bot_token} stored in Colab and it's a valid key from telegram")
  raise e

!pip3 install requests

import requests

url = f"https://api.telegram.org/bot{userdata.get(telegram_bot_token)}/getUpdates"
response = requests.get(url)

print("Status Code:", response.status_code)
print("Response Content:", response.content)

response = requests.get(url)

print("Status Code:", response.status_code)
print("Response Content:", response.content)

import telebot

BOT_TOKEN = userdata.get(telegram_bot_token)
bot= telebot.TeleBot(BOT_TOKEN)

@bot.message_handler(commands = ['start'])
def on_start(message):
    bot.send_message(message.chat.id, "Hello frend, need help with some readings?")

@bot.message_handler(func=lambda msg: True)
def on_message(message):
	bot.reply_to(message, message.text)

from google.colab import userdata

hugging_face_token_secret = 'HF_TOKEN'  # @param {type: "string"}

try:
  TELEGRAM_API_KEY=userdata.get(hugging_face_token_secret)
except userdata.SecretNotFoundError as e:
   print(f'Secret not found\n\nThis expects you to create a secret named {hugging_face_token_secret} in Colab\n\nGot to that url and create a write token (https://huggingface.co/settings/tokens)\n\nStore that in the secrets section on the left side of the notebook (key icon)\n\nName the secret {hugging_face_token_secret}')
   raise e
except userdata.NotebookAccessError as e:
  print(f'You need to grant this notebook access to the {hugging_face_token_secret} secret in order for the notebook to access your Telegram Bot on your behalf.')
  raise e
except Exception as e:
  # unknown error
  print(f"There was an unknown error. Ensure you have a secret {hugging_face_token_secret} stored in Colab and it's a valid key from telegram")
  raise e

!pip3 install langchain transformers

!pip3 install langchain(llm)



import os
from langchain_community.llms import HuggingFaceHub
os.environ["HUGGINGFACEHUB_API_TOKEN"] = userdata.get(hugging_face_token_secret)

from transformers import AutoTokenizer

from langchain_core.retrievers import BaseRetriever
from langchain_core.callbacks import CallbackManagerForRetrieverRun
from langchain_core.documents import Document
from typing import List


class CustomRetriever(BaseRetriever):

    def _get_relevant_documents(
        self, query: str, *, run_manager: CallbackManagerForRetrieverRun
    ) -> List[Document]:
        return [Document(page_content=query)]

retriever = CustomRetriever()

class LLM:
  def __init__(self):
    model_string = "mistralai/Mistral-7B-Instruct-v0.2"
    self.chat = []
    self.llm = HuggingFaceHub(repo_id=model_string, model_kwargs={"temperature": 0.5, "max_length":64,"max_new_tokens":512})
    self.tokenizer = AutoTokenizer.from_pretrained(model_string)

  def get_reply(self, instruction):
    instruction_with_context = append_documents_to_instruction(instruction)
    self.chat.append({"role" : "user", "content" : instruction_with_context})

    prompt = self.tokenizer.apply_chat_template(self.chat, tokenize=False)
    reply = self.llm.invoke(prompt)
    self.chat.append({"role" : "assistant", "content" : reply})
    return reply

def append_documents_to_instruction(instruction):
    instruction_with_documents = f'''Answer the following question, making use of the documents provided below if they are relevant. Do not use those documents and do not mention them if you deem that they do not contain any relevant information. Do not mention the id of the documents. If a document is relevant, add the source of the information by adding a link to the exact url that was used. For that use the 'source' field of the relevant document.
Question: {instruction}

    '''

    docs = retriever.get_relevant_documents(instruction)

    if len(docs) == 0: # If there are no relevant documents, just return the original instruction
        return instruction

    instruction_with_documents += "Documents:\n"

    for i, doc in enumerate(docs):
        instruction_with_documents += f'''- {doc.metadata}
            Content: {doc.page_content}
'''
    return instruction_with_documents

llm = LLM()

!pip3 install faiss-cpu

!pip3 install pypdf

def dl_file(message):
    import requests
    file_info = bot.get_file(message.document.file_id)

    download_url = f"https://api.telegram.org/file/bot{bot.token}/{file_info.file_path}"
    response = requests.get(download_url)

    if response.status_code == 200:
        with open(message.document.file_name, 'wb') as file:
            file.write(response.content)
        return True
    else:
        return False

from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.storage import LocalFileStore
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings
from langchain.embeddings import CacheBackedEmbeddings


def init_bot():
  bot = telebot.TeleBot(BOT_TOKEN)

  @bot.message_handler(commands=['start'])
  def on_start(message):
      bot.send_message(message.chat.id, "Hello frend, need help with some readings?")

  @bot.message_handler(commands=['newchat'])
  def on_new_chat(message):
    llm.chat = []
    bot.reply_to(message,  "Starting new chat!")

  @bot.message_handler(content_types=['document'])
  def on_document(message):
    if message.document.mime_type == 'application/pdf':
        reply = bot.reply_to(message, "‚¨áÔ∏è Downloading file ‚¨áÔ∏è")

        if not dl_file(message):
            bot.edit_message_text("‚ùå Failed to download file", reply.chat.id, reply.message_id)
            return

        bot.edit_message_text("üóÉÔ∏è Adding file to database üóÉÔ∏è", reply.chat.id, reply.message_id)

        loader = PyPDFLoader(message.document.file_name)

        pages = loader.load_and_split()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)

        chunks = text_splitter.transform_documents(pages)

        store = LocalFileStore("./cache")
        core_embeddings_model = HuggingFaceInferenceAPIEmbeddings(
           api_key = userdata.get(hugging_face_token_secret),
           model_name="sentence-transformers/all-MiniLM-l6-v2")

        embedder = CacheBackedEmbeddings.from_bytes_store(core_embeddings_model, store)

        vectorstore = FAISS.from_documents(chunks,embedder)

        vectorstore.add_documents(chunks)

        bot.edit_message_text("‚úÖ PDF received and added to database", reply.chat.id, reply.message_id)
    else:
        bot.reply_to(message, "For the moment, I only support indexing PDF files. Please send a PDF file.")


  @bot.message_handler(func=lambda msg: True)
  def on_message(message):
      print(f"Message received! {message}")
      reply = llm.get_reply(message.text)
      bot.reply_to(message, reply)

  return bot

bot = init_bot()
llm.chat = ["send me the article!"]
bot.infinity_polling()
